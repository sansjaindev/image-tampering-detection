{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "ORIGINAL Images count: 730\n",
      "TAMPERED Images count: 730\n",
      "\n",
      "Validation data:\n",
      "ORIGINAL Images count: 314\n",
      "TAMPERED Images count: 314\n"
     ]
    }
   ],
   "source": [
    "def get_count(dir_path):    \n",
    "    for path in os.listdir(dir_path):\n",
    "        count = 0\n",
    "        for item in os.listdir(dir_path + '\\\\' + path):\n",
    "            count += 1\n",
    "        print(path, 'Images count:', count)\n",
    "\n",
    "\n",
    "print('Training data:')\n",
    "get_count('C:\\\\Users\\\\sansk\\\\Desktop\\\\archive\\\\TRAINING_CG-1050\\\\TRAINING')\n",
    "\n",
    "print('\\nValidation data:')\n",
    "get_count('C:\\\\Users\\\\sansk\\\\Desktop\\\\archive\\\\VALIDATION_CG-1050\\\\VALIDATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (150,150)\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "training_data = datagen.flow_from_directory('C:\\\\Users\\\\sansk\\\\Desktop\\\\archive\\\\TRAINING_CG-1050\\\\TRAINING',\n",
    "                                            target_size=img_shape,\n",
    "                                            color_mode='rgb',\n",
    "                                            batch_size=64,\n",
    "                                            seed=32,\n",
    "                                            interpolation='bicubic')\n",
    "\n",
    "validation_data = datagen.flow_from_directory('C:\\\\Users\\\\sansk\\\\Desktop\\\\archive\\\\VALIDATION_CG-1050\\\\VALIDATION',\n",
    "                                                    target_size=img_shape,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=64,\n",
    "                                                    seed=32,\n",
    "                                                    interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=2, activation=\"relu\", input_shape=(150, 150, 3)))\n",
    "model.add(tensorflow_addons.layers.InstanceNormalization(axis=-1))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', strides=2))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, 'relu'))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(2, 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.6243 - accuracy: 0.6438 - val_loss: 0.6342 - val_accuracy: 0.6465 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 100s 4s/step - loss: 0.6257 - accuracy: 0.6466 - val_loss: 0.6342 - val_accuracy: 0.6449 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6258 - accuracy: 0.6459 - val_loss: 0.6342 - val_accuracy: 0.6449 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 93s 4s/step - loss: 0.6226 - accuracy: 0.6452 - val_loss: 0.6342 - val_accuracy: 0.6449 - lr: 1.0000e-07\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 96s 4s/step - loss: 0.6190 - accuracy: 0.6452 - val_loss: 0.6342 - val_accuracy: 0.6449 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec42389df0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2)\n",
    "model.fit(training_data, validation_data=validation_data, epochs=40, callbacks=[early_stop, reduce_lr])\n",
    "# model.fit(training_data, validation_data=validation_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "epochs = [i for i in range(len(loss))]\n",
    "plt.plot(epochs,loss)\n",
    "plt.plot(epochs,val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,acc)\n",
    "plt.plot(epochs,val_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(path):\n",
    "    image=cv2.imread(path)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    image=cv2.resize(image,(150,150))\n",
    "    image=image.reshape(1,150,150,3)\n",
    "    prediction=np.argmax(model.predict(image))\n",
    "    labels=['Original','Tampered']\n",
    "    return labels[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('C:\\\\Users\\\\sansk\\\\Desktop\\\\archive\\\\TRAINING_CG-1050\\\\TRAINING\\\\ORIGINAL\\\\Im100_2_cm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('C:\\\\Users\\\\sansk\\\\Downloads\\\\a.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
